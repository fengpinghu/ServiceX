{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to ServiceX ServiceX , a component of the IRIS-HEP Intelligent Data Delivery Service, is an experiment-agnostic service to enable on-demand columnar data delivery tailored for nearly interactive, high performance, array-based Pythonic analyses. It provides a uniform backend interface to data storage services and an intuitive frontend for users to enable columnar transformations from multiple different data formats and organizational structures.","title":"Home"},{"location":"#welcome-to-servicex","text":"ServiceX , a component of the IRIS-HEP Intelligent Data Delivery Service, is an experiment-agnostic service to enable on-demand columnar data delivery tailored for nearly interactive, high performance, array-based Pythonic analyses. It provides a uniform backend interface to data storage services and an intuitive frontend for users to enable columnar transformations from multiple different data formats and organizational structures.","title":"Welcome to ServiceX"},{"location":"about/","text":"Gortyniaco esse Parente cum essemus felix iam excussa castra Lorem markdownum imagine Cecropis aestus. Cingo avem possunt constitit alvum et genus aut plurima, nomen, non cingentibus raptaque parentum, sit aut? Non equidem amans subito, oscula contingent Sparten excutiuntque potes. Verba aut erit timorem, usum conplexibus foret nec clausit; quod? Animum tacito Dextra Acheronte meorum Penetralia consistere bonis In enim multiplicique dextra Est elisa, unum sed et custodes lacerum . Obrutaque et tectus tempus utque, venit quoque parentum tempore honores cessant qui movent me fer. Te quam aut trium et damna facit vestigia agros nostris manus. Macies in atra templis volucri nudae praecordia sua promissaque mihi. Alienae per est abstulit, dent sensit Anchisae imagine parva indicium; ad adhuc nisi populo terris signorum saecula volvitur. Hecabesque muta, formam facta; Hectoreis nobilitas terga Cephalus o resque in valet. Detinuit relicta tenaci Atque intrare ut equorum Alcathoen adspergit ingenti e tutus, labores morientibus semper Oenidae et. Acutae glandes dextrae oscula. Fert tecta animoque misit contulit, et gemuit et aetas maximus ignes. Tremulo aegro supremumque minimam arbore. Umero callem nexilibusque Hesperiosque postquam, vox per quod fieri concordes poterat dentes terrae. Festumque ad nisi Philemona saecula. Ecce stipite fugante , arma suos tendens dies Dictaei verterit in cum enim sublimis moles rorantia vertice tigres. Acta vellere cum est est cruribus motos locumque Lucifer, otia. Iubet arsuris corpora vincite ipsa deus tetigit. Virgo et loqui pugnacem cautum novitate. Simois illa, virtus belli: silvis dignum. Sed texta sinu peremi choreas et paratus nomen . Adeo cur sepulchro et ita similes perdite Quirites peioris lentum adest, crinales muris doctas adspexisse. Speciem hostibus templo patrios ; est fugam iram at caeli iam iubet es. Servantis senior ipse videre rapuere fertur relinquit ab Colcha hausta; vero Elide, via dura et. Quibus silentia neque Phoci inundet at se unde namque, unca ripis. In sibi tactuque meritique parsque preces. Ad solis : mixto acceperat conanti iustissime Eurus, et visu; te e veluti crescit, quaeque, sub.","title":"Gortyniaco esse"},{"location":"about/#gortyniaco-esse","text":"","title":"Gortyniaco esse"},{"location":"about/#parente-cum-essemus-felix-iam-excussa-castra","text":"Lorem markdownum imagine Cecropis aestus. Cingo avem possunt constitit alvum et genus aut plurima, nomen, non cingentibus raptaque parentum, sit aut? Non equidem amans subito, oscula contingent Sparten excutiuntque potes. Verba aut erit timorem, usum conplexibus foret nec clausit; quod? Animum tacito Dextra Acheronte meorum Penetralia consistere bonis In enim multiplicique dextra Est elisa, unum sed et custodes lacerum . Obrutaque et tectus tempus utque, venit quoque parentum tempore honores cessant qui movent me fer. Te quam aut trium et damna facit vestigia agros nostris manus. Macies in atra templis volucri nudae praecordia sua promissaque mihi. Alienae per est abstulit, dent sensit Anchisae imagine parva indicium; ad adhuc nisi populo terris signorum saecula volvitur. Hecabesque muta, formam facta; Hectoreis nobilitas terga Cephalus o resque in valet.","title":"Parente cum essemus felix iam excussa castra"},{"location":"about/#detinuit-relicta-tenaci","text":"Atque intrare ut equorum Alcathoen adspergit ingenti e tutus, labores morientibus semper Oenidae et. Acutae glandes dextrae oscula. Fert tecta animoque misit contulit, et gemuit et aetas maximus ignes. Tremulo aegro supremumque minimam arbore. Umero callem nexilibusque Hesperiosque postquam, vox per quod fieri concordes poterat dentes terrae. Festumque ad nisi Philemona saecula. Ecce stipite fugante , arma suos tendens dies Dictaei verterit in cum enim sublimis moles rorantia vertice tigres. Acta vellere cum est est cruribus motos locumque Lucifer, otia. Iubet arsuris corpora vincite ipsa deus tetigit. Virgo et loqui pugnacem cautum novitate. Simois illa, virtus belli: silvis dignum. Sed texta sinu peremi choreas et paratus nomen . Adeo cur sepulchro et ita similes perdite Quirites peioris lentum adest, crinales muris doctas adspexisse. Speciem hostibus templo patrios ; est fugam iram at caeli iam iubet es. Servantis senior ipse videre rapuere fertur relinquit ab Colcha hausta; vero Elide, via dura et. Quibus silentia neque Phoci inundet at se unde namque, unca ripis. In sibi tactuque meritique parsque preces. Ad solis : mixto acceperat conanti iustissime Eurus, et visu; te e veluti crescit, quaeque, sub.","title":"Detinuit relicta tenaci"},{"location":"development/","text":"Development So you want to get involved! The developers welcome community input. The central development area with all ServiceX repositories can be found here . The core steps are shown in the diagram below. Testing new changes [Instructions for testing new changes. Broadly (1) setup testing environment via conda or virtualenv , (2) clone the appropriate repository, (3) run python -m pip install -e .[test] to set up the necessary packages in the environment, and (4) run the tests via pytests .] Deploying ServiceX on a Kubernetes cluster The entire ServiceX stack can be installed using the helm chart contained here . Below is a set of developer instructions for deploying a production-ready instance of ServiceX on a Kubernetes cluster. Deployment requires access to a Kubernetes cluster. You\u2019ll need to install and set up kubectl (see Install and Set Up kubectl ) and Helm 3 (see Installing Helm ). Next configure kubectl to access the appropriate namespace on the cluster with the kubeconfig file located at ~/.kube/config . For complete control over the deployment values in the ServiceX Helm chart, it\u2019s recommended to check out the develop branch of ServiceX from GitHub: git clone https://github.com/ssl-hep/ServiceX.git cd ServiceX git checkout develop Add and update the ServiceX Helm chart: helm repo add ssl-hep https://ssl-hep.github.io/ssl-helm-charts/ helm repo update helm dependency update servicex ServiceX may require some modifications to the default deployment values to run on your cluster. In particular, you\u2019ll need your CERN grid certificate to communicate with Rucio. You can see the default values in servicex/values.yaml . These values can be overridden via a separate yaml file. For example, to run on SSL-RIVER, cat <<EOF > river-values.yaml app: auth: true adminUser: admin adminPassword: eto2ipiis1 ingress: enabled: true didFinder: tag: v1.0-rc.1 pullPolicy: Always codeGen: # image: sslhep/servicex_code_gen_func_adl_uproot image: sslhep/servicex_code_gen_func_adl_xaod rabbitmq: service: type: NodePort nodePort: 30672 minio: ingress: enabled: true hosts: - \"servicex-minio.uc.ssl-hep.org\" gridAccount: bgalewsk EOF With the appropriate values, it is now possible to deploy ServiceX via the Helm chart: helm install -f river-values.yaml --version v1.0.0-rc.1 rc1-xaod ssl-hep/servicex Initial deployment is typically rapid, with RabbitMQ requiring up to a minute to complete its initialization. After this all the pods of the new deployment should be ready. If you check the status of the pods via kubectl get pods You should soon find that your setup looks comparable to this: NAME READY STATUS RESTARTS AGE servicex-1579021789-code-gen-7cd998d5b6-nwtgv 1/1 Running 0 49m servicex-1579021789-did-finder-7c5cbb4575-52wxf 1/1 Running 0 49m servicex-1579021789-minio-78b55bfdf8-mbmmf 1/1 Running 0 49m servicex-1579021789-preflight-b748b4dfd-qqt89 1/1 Running 4 49m servicex-1579021789-rabbitmq-0 1/1 Running 0 49m servicex-1579021789-servicex-app-98779c79c-cvmqx 1/1 Running 3 49m servicex-1579021789-x509-secrets-74f4bcc8bb-5kqvb 1/1 Running 0 49m The new ServiceX deployment should now be ready for business. To try a 10TB scale test check ServiceX_scaleTest .","title":"Development"},{"location":"development/#development","text":"So you want to get involved! The developers welcome community input. The central development area with all ServiceX repositories can be found here . The core steps are shown in the diagram below.","title":"Development"},{"location":"development/#testing-new-changes","text":"[Instructions for testing new changes. Broadly (1) setup testing environment via conda or virtualenv , (2) clone the appropriate repository, (3) run python -m pip install -e .[test] to set up the necessary packages in the environment, and (4) run the tests via pytests .]","title":"Testing new changes"},{"location":"development/#deploying-servicex-on-a-kubernetes-cluster","text":"The entire ServiceX stack can be installed using the helm chart contained here . Below is a set of developer instructions for deploying a production-ready instance of ServiceX on a Kubernetes cluster. Deployment requires access to a Kubernetes cluster. You\u2019ll need to install and set up kubectl (see Install and Set Up kubectl ) and Helm 3 (see Installing Helm ). Next configure kubectl to access the appropriate namespace on the cluster with the kubeconfig file located at ~/.kube/config . For complete control over the deployment values in the ServiceX Helm chart, it\u2019s recommended to check out the develop branch of ServiceX from GitHub: git clone https://github.com/ssl-hep/ServiceX.git cd ServiceX git checkout develop Add and update the ServiceX Helm chart: helm repo add ssl-hep https://ssl-hep.github.io/ssl-helm-charts/ helm repo update helm dependency update servicex ServiceX may require some modifications to the default deployment values to run on your cluster. In particular, you\u2019ll need your CERN grid certificate to communicate with Rucio. You can see the default values in servicex/values.yaml . These values can be overridden via a separate yaml file. For example, to run on SSL-RIVER, cat <<EOF > river-values.yaml app: auth: true adminUser: admin adminPassword: eto2ipiis1 ingress: enabled: true didFinder: tag: v1.0-rc.1 pullPolicy: Always codeGen: # image: sslhep/servicex_code_gen_func_adl_uproot image: sslhep/servicex_code_gen_func_adl_xaod rabbitmq: service: type: NodePort nodePort: 30672 minio: ingress: enabled: true hosts: - \"servicex-minio.uc.ssl-hep.org\" gridAccount: bgalewsk EOF With the appropriate values, it is now possible to deploy ServiceX via the Helm chart: helm install -f river-values.yaml --version v1.0.0-rc.1 rc1-xaod ssl-hep/servicex Initial deployment is typically rapid, with RabbitMQ requiring up to a minute to complete its initialization. After this all the pods of the new deployment should be ready. If you check the status of the pods via kubectl get pods You should soon find that your setup looks comparable to this: NAME READY STATUS RESTARTS AGE servicex-1579021789-code-gen-7cd998d5b6-nwtgv 1/1 Running 0 49m servicex-1579021789-did-finder-7c5cbb4575-52wxf 1/1 Running 0 49m servicex-1579021789-minio-78b55bfdf8-mbmmf 1/1 Running 0 49m servicex-1579021789-preflight-b748b4dfd-qqt89 1/1 Running 4 49m servicex-1579021789-rabbitmq-0 1/1 Running 0 49m servicex-1579021789-servicex-app-98779c79c-cvmqx 1/1 Running 3 49m servicex-1579021789-x509-secrets-74f4bcc8bb-5kqvb 1/1 Running 0 49m The new ServiceX deployment should now be ready for business. To try a 10TB scale test check ServiceX_scaleTest .","title":"Deploying ServiceX on a Kubernetes cluster"},{"location":"examples/","text":"Examples Some intro to the various ways in which the service can be used. Will add more here, but for now the best info is probably in the notebooks below. Transform xAOD files from Rucio How to transform xAOD files from Rucio Extract columns from flat ntuples in Rucio How to extract columns from flat ntuples Transform a list of miniAOD files Some cutting-edge stuff for CMS formats","title":"Examples"},{"location":"examples/#examples","text":"Some intro to the various ways in which the service can be used. Will add more here, but for now the best info is probably in the notebooks below.","title":"Examples"},{"location":"examples/#transform-xaod-files-from-rucio","text":"How to transform xAOD files from Rucio","title":"Transform xAOD files from Rucio"},{"location":"examples/#extract-columns-from-flat-ntuples-in-rucio","text":"How to extract columns from flat ntuples","title":"Extract columns from flat ntuples in Rucio"},{"location":"examples/#transform-a-list-of-miniaod-files","text":"Some cutting-edge stuff for CMS formats","title":"Transform a list of miniAOD files"},{"location":"installation/","text":"Prerequisites for users Interacting with a central instance of ServiceX (as opposed to setting up your own instance) consists in two parts: getting authenticated in the system by an administrator and installing the appropriate client library. Getting authenticated There are two instances of ServiceX, one to transform xAOD input files and one to transform flat ntuples, and you must be separately authenticated to each in order to use them. You can go to the xAOD version or the Uproot version and put in the username and password for your requested account. In addition, both instances rely on ATLAS credentials to access Rucio, so you must be a member of the ATLAS VO to use them. The ServiceX admins will seek to personally accept pending accounts, so once you've registered send a message to the admins (Ben Galewsky or Marc Weinberg, e.g. via Slack ) and they will authorize any pending requests. Once you\u2019re authenticated by an administrator your account will have access to ServiceX, and you\u2019ll be able to put in transform requests. Installing the client Python library The documentation for the ServiceX client is shown here . It's also useful to employ functions from the func-adl libraries ( for xAOD or Uproot ). To interact with ServiceX via the client library you\u2019ll need an environment running Python 3.7: python -m pip install servicex==2.0.0b9 python -m pip install func-adl-xAOD==1.1.0b4 In the Python prompt you can import the libraries and make a request using your registered username and password.","title":"Getting started"},{"location":"installation/#prerequisites-for-users","text":"Interacting with a central instance of ServiceX (as opposed to setting up your own instance) consists in two parts: getting authenticated in the system by an administrator and installing the appropriate client library.","title":"Prerequisites for users"},{"location":"installation/#getting-authenticated","text":"There are two instances of ServiceX, one to transform xAOD input files and one to transform flat ntuples, and you must be separately authenticated to each in order to use them. You can go to the xAOD version or the Uproot version and put in the username and password for your requested account. In addition, both instances rely on ATLAS credentials to access Rucio, so you must be a member of the ATLAS VO to use them. The ServiceX admins will seek to personally accept pending accounts, so once you've registered send a message to the admins (Ben Galewsky or Marc Weinberg, e.g. via Slack ) and they will authorize any pending requests. Once you\u2019re authenticated by an administrator your account will have access to ServiceX, and you\u2019ll be able to put in transform requests.","title":"Getting authenticated"},{"location":"installation/#installing-the-client-python-library","text":"The documentation for the ServiceX client is shown here . It's also useful to employ functions from the func-adl libraries ( for xAOD or Uproot ). To interact with ServiceX via the client library you\u2019ll need an environment running Python 3.7: python -m pip install servicex==2.0.0b9 python -m pip install func-adl-xAOD==1.1.0b4 In the Python prompt you can import the libraries and make a request using your registered username and password.","title":"Installing the client Python library"},{"location":"introduction/","text":"Introduction The High Luminosity Large Hadron Collider (HL-LHC) faces enormous computational challenges in the 2020s. The HL-LHC will produce exabytes of data each year, with increasingly complex event structure due to high pileup conditions. The ATLAS and CMS experiments will record ~ 10 times as much data from ~ 100 times as many collisions as were used to discover the Higgs boson. Columnar data delivery ServiceX seeks to enable on-demand data delivery of columnar data in a variety of formats for physics analyses. It provides a uniform backend to data storage services, ensuring the user doesn't have to know how or where the data is stored, and is capable of on-the-fly data transformations into a variety of formats (ROOT files, Arrow arrays, Parquet files, ...) The service offers preprocessing functionality via an analysis description language called func-adl that allows users to filter events, request columns, and even compute new variables. This enables the user to start from any format and extract only the data needed for an analysis. ServiceX is designed to feed columns to a user running an analysis (e.g. via Awkward or Coffea tools) based on the results of a query designed by the user.","title":"Introduction"},{"location":"introduction/#introduction","text":"The High Luminosity Large Hadron Collider (HL-LHC) faces enormous computational challenges in the 2020s. The HL-LHC will produce exabytes of data each year, with increasingly complex event structure due to high pileup conditions. The ATLAS and CMS experiments will record ~ 10 times as much data from ~ 100 times as many collisions as were used to discover the Higgs boson.","title":"Introduction"},{"location":"introduction/#columnar-data-delivery","text":"ServiceX seeks to enable on-demand data delivery of columnar data in a variety of formats for physics analyses. It provides a uniform backend to data storage services, ensuring the user doesn't have to know how or where the data is stored, and is capable of on-the-fly data transformations into a variety of formats (ROOT files, Arrow arrays, Parquet files, ...) The service offers preprocessing functionality via an analysis description language called func-adl that allows users to filter events, request columns, and even compute new variables. This enables the user to start from any format and extract only the data needed for an analysis. ServiceX is designed to feed columns to a user running an analysis (e.g. via Awkward or Coffea tools) based on the results of a query designed by the user.","title":"Columnar data delivery"},{"location":"outreach/","text":"Outreach Information available in the HEP community. Presentations List of talks/posters to the HEP community on ServiceX IRIS-HEP Poster Session 2020 at Princeton University ServiceX talk at CHEP 2019 ServiceX talk at HSF DAWG \u2013 DOMA Access meeting Tutorials A link to our tutorials. We currently have two: A streaming example for xAOD files using func_adl An example using hep_tables for the frontend","title":"Outreach"},{"location":"outreach/#outreach","text":"Information available in the HEP community.","title":"Outreach"},{"location":"outreach/#presentations","text":"List of talks/posters to the HEP community on ServiceX IRIS-HEP Poster Session 2020 at Princeton University ServiceX talk at CHEP 2019 ServiceX talk at HSF DAWG \u2013 DOMA Access meeting","title":"Presentations"},{"location":"outreach/#tutorials","text":"A link to our tutorials. We currently have two: A streaming example for xAOD files using func_adl An example using hep_tables for the frontend","title":"Tutorials"},{"location":"requests/","text":"Using ServiceX A transformation request is a specifically formatted request sent to ServiceX. It includes information on what input dataset is to be used, what preselection is to be applied (including computation of new columns, if any), and what columns should be returned to the user. Selecting endpoints Each request requires two endpoints, one corresponding to the service itself, and one for the output of the request. The current available endpoints are shown below. Endpoint Type Location Experiment Input rc1-xaod-servicex.uc.ssl-hep.org ServiceX SSL-RIVER ATLAS xAOD files rc1-xaod-minio.uc.ssl-hep.org MinIO SSL-RIVER ATLAS xAOD files rc1-uproot-servicex.uc.ssl-hep.org ServiceX SSL-RIVER ATLAS Flat ntuples rc1-uproot-minio.uc.ssl-hep.org MinIO SSL-RIVER ATLAS Flat ntuples Creating a request via func_adl In order to use func_adl directly we start with a Qastle query as our input. The following is a query designed to extract the transverse momenta of a jet collection in some xAOD-formatted dataset: my_query = \"(call ResultTTree\" \\ \"(call Select\" \\ \"(call SelectMany\" \\ \"(call EventDataset (list 'localds:bogus'))\" \\ \"(lambda (list e) (call (attr e 'Jets') 'AntiKt4EMTopoJets'))\" \\ \") (lambda (list j) (/ (call (attr j 'pt')) 1000.0))\" \\ \") (list 'JetPt') 'analysis' 'junk.root')\" Given this input, we can produce output containing the transverse momenta of all jets in an ATLAS xAOD file. We start by specifying the structure of the ServiceX request: import servicex dataset = \u2018mc15_13TeV:mc15_13TeV.361106.PowhegPythia8EvtGen_AZNLOCTEQ6L1_Zee.merge.DAOD_STDM3.e3601_s2576_s2132_r6630_r6264_p2363_tid05630052_00\u2019 sx_endpoint = 'http://rc1-xaod-servicex.uc.ssl-hep.org' minio_endpoint = 'rc1-xaod-minio.uc.ssl-hep.org' ds = servicex.ServiceXDataset( dataset, servicex.ServiceXAdaptor(sx_endpoint, username='mweinberg', password='XXXXXXXXX'), servicex.MinioAdaptor(minio_endpoint) ) Once we have this, we can call ServiceX to output the results of our query in a convenient format: r = servicex.get_data_pandas_df(my_query) print(r) After about 1--2 minutes, this prints a data frame with a single column for the transverse momenta. A badly formatted query, or a problem with the file in the backend, will cause an exception to be thrown. Note that there are also tools like the one here that are capable of turning a text file of requested columns (e.g. here ) into a complete Qastle query. Using helper functions to construct a query For all but the simplest single-column requests, creating a Qastle query as input can be quite cumbersome. func_adl provides additional libraries to construct queries. For example, we can perform the same request using the func_adl_xAOD library: import func_adl_xAOD f_ds = func_adl_xAOD.ServiceXDatasetSource(ds) r = f_ds \\ .SelectMany('lambda e: e.Jets(\"AntiKt4EMTopoJets\")') \\ .Select('lambda j: j.pt() / 1000.0') \\ .AsPandasDF('JetPt') \\ .value() print(r) Note that the Select() function transforms the input dataset by allowing you to select only objects matching the selection criteria (in this case only the pT attribute of the jet collection). Meanwhile the function SelectMany() shifts the hierarchy by returning a list of lists (in this case a list of events, each containing a separate list of jets). AsPandasDF() formats the output as a Pandas dataframe, and value() is responsible for executing the query. As a more realistic example, we can construct a request for the four-momenta of the Electron and Muon collection. In this case let's output the results as a set of AwkwardArrays: r = f_ds \\ .Select('lambda e: (e.Electrons(\"Electrons\"), e.Muons(\"Muons\"))') \\ .Select('lambda ls: (ls[0].Select(lambda e: e.pt()), \\ ls[0].Select(lambda e: e.eta()), \\ ls[0].Select(lambda e: e.phi()), \\ ls[0].Select(lambda e: e.e()), \\ ls[1].Select(lambda m: m.pt()), \\ ls[1].Select(lambda m: m.eta()), \\ ls[1].Select(lambda m: m.phi()), \\ ls[1].Select(lambda m: m.e()))') \\ .AsAwkwardArray(('ElePt', 'EleEta', 'ElePhi', 'EleE', 'MuPt', 'MuEta', 'MuPhi', 'MuE')) \\ .value() Because the output is an AwkwardArray, which can handle the variable-size set of objects for each event, it is no longer necessary to use the SelectMany() function as above. Next, let's consider the case where we wish to return information only for those jets with a pT passing some threshold cut. This can be done via the Where() function: r = f_ds \\ .SelectMany('lambda e: e.Jets(\"AntiKt4EMTopoJets\")') \\ .Where('lambda j: j.pt() / 1000.0 > 30.0') \\ .Select('lambda j: j.eta()') \\ .AsPandasDF('JetPt') \\ .value() which returns a dataframe with the eta values of all jets whose pT is above 30 GeV. Choosing the output There are currently three choices for formatting the output of a ServiceX request: AsPandasDF returns the output as a Pandas dataframe , AsROOTTree returns the output as a flat TTree , and AsAwkwardArray returns the output as an Awkward array suitable for use with uproot .","title":"Specifying a request"},{"location":"requests/#using-servicex","text":"A transformation request is a specifically formatted request sent to ServiceX. It includes information on what input dataset is to be used, what preselection is to be applied (including computation of new columns, if any), and what columns should be returned to the user.","title":"Using ServiceX"},{"location":"requests/#selecting-endpoints","text":"Each request requires two endpoints, one corresponding to the service itself, and one for the output of the request. The current available endpoints are shown below. Endpoint Type Location Experiment Input rc1-xaod-servicex.uc.ssl-hep.org ServiceX SSL-RIVER ATLAS xAOD files rc1-xaod-minio.uc.ssl-hep.org MinIO SSL-RIVER ATLAS xAOD files rc1-uproot-servicex.uc.ssl-hep.org ServiceX SSL-RIVER ATLAS Flat ntuples rc1-uproot-minio.uc.ssl-hep.org MinIO SSL-RIVER ATLAS Flat ntuples","title":"Selecting endpoints"},{"location":"requests/#creating-a-request-via-func_adl","text":"In order to use func_adl directly we start with a Qastle query as our input. The following is a query designed to extract the transverse momenta of a jet collection in some xAOD-formatted dataset: my_query = \"(call ResultTTree\" \\ \"(call Select\" \\ \"(call SelectMany\" \\ \"(call EventDataset (list 'localds:bogus'))\" \\ \"(lambda (list e) (call (attr e 'Jets') 'AntiKt4EMTopoJets'))\" \\ \") (lambda (list j) (/ (call (attr j 'pt')) 1000.0))\" \\ \") (list 'JetPt') 'analysis' 'junk.root')\" Given this input, we can produce output containing the transverse momenta of all jets in an ATLAS xAOD file. We start by specifying the structure of the ServiceX request: import servicex dataset = \u2018mc15_13TeV:mc15_13TeV.361106.PowhegPythia8EvtGen_AZNLOCTEQ6L1_Zee.merge.DAOD_STDM3.e3601_s2576_s2132_r6630_r6264_p2363_tid05630052_00\u2019 sx_endpoint = 'http://rc1-xaod-servicex.uc.ssl-hep.org' minio_endpoint = 'rc1-xaod-minio.uc.ssl-hep.org' ds = servicex.ServiceXDataset( dataset, servicex.ServiceXAdaptor(sx_endpoint, username='mweinberg', password='XXXXXXXXX'), servicex.MinioAdaptor(minio_endpoint) ) Once we have this, we can call ServiceX to output the results of our query in a convenient format: r = servicex.get_data_pandas_df(my_query) print(r) After about 1--2 minutes, this prints a data frame with a single column for the transverse momenta. A badly formatted query, or a problem with the file in the backend, will cause an exception to be thrown. Note that there are also tools like the one here that are capable of turning a text file of requested columns (e.g. here ) into a complete Qastle query.","title":"Creating a request via func_adl"},{"location":"requests/#using-helper-functions-to-construct-a-query","text":"For all but the simplest single-column requests, creating a Qastle query as input can be quite cumbersome. func_adl provides additional libraries to construct queries. For example, we can perform the same request using the func_adl_xAOD library: import func_adl_xAOD f_ds = func_adl_xAOD.ServiceXDatasetSource(ds) r = f_ds \\ .SelectMany('lambda e: e.Jets(\"AntiKt4EMTopoJets\")') \\ .Select('lambda j: j.pt() / 1000.0') \\ .AsPandasDF('JetPt') \\ .value() print(r) Note that the Select() function transforms the input dataset by allowing you to select only objects matching the selection criteria (in this case only the pT attribute of the jet collection). Meanwhile the function SelectMany() shifts the hierarchy by returning a list of lists (in this case a list of events, each containing a separate list of jets). AsPandasDF() formats the output as a Pandas dataframe, and value() is responsible for executing the query. As a more realistic example, we can construct a request for the four-momenta of the Electron and Muon collection. In this case let's output the results as a set of AwkwardArrays: r = f_ds \\ .Select('lambda e: (e.Electrons(\"Electrons\"), e.Muons(\"Muons\"))') \\ .Select('lambda ls: (ls[0].Select(lambda e: e.pt()), \\ ls[0].Select(lambda e: e.eta()), \\ ls[0].Select(lambda e: e.phi()), \\ ls[0].Select(lambda e: e.e()), \\ ls[1].Select(lambda m: m.pt()), \\ ls[1].Select(lambda m: m.eta()), \\ ls[1].Select(lambda m: m.phi()), \\ ls[1].Select(lambda m: m.e()))') \\ .AsAwkwardArray(('ElePt', 'EleEta', 'ElePhi', 'EleE', 'MuPt', 'MuEta', 'MuPhi', 'MuE')) \\ .value() Because the output is an AwkwardArray, which can handle the variable-size set of objects for each event, it is no longer necessary to use the SelectMany() function as above. Next, let's consider the case where we wish to return information only for those jets with a pT passing some threshold cut. This can be done via the Where() function: r = f_ds \\ .SelectMany('lambda e: e.Jets(\"AntiKt4EMTopoJets\")') \\ .Where('lambda j: j.pt() / 1000.0 > 30.0') \\ .Select('lambda j: j.eta()') \\ .AsPandasDF('JetPt') \\ .value() which returns a dataframe with the eta values of all jets whose pT is above 30 GeV.","title":"Using helper functions to construct a query"},{"location":"requests/#choosing-the-output","text":"There are currently three choices for formatting the output of a ServiceX request: AsPandasDF returns the output as a Pandas dataframe , AsROOTTree returns the output as a flat TTree , and AsAwkwardArray returns the output as an Awkward array suitable for use with uproot .","title":"Choosing the output"}]}